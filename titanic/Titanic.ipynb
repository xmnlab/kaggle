{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#VARIABLE-DESCRIPTIONS:\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>VARIABLE DESCRIPTIONS:</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bf6d6733-3a02-4507-b9d1-f1308c35fa58"
   },
   "source": [
    "# VARIABLE DESCRIPTIONS:\n",
    "\n",
    "* survival        Survival            (0 = No; 1 = Yes)\n",
    "* pclass          Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* name            Name\n",
    "* sex             Sex\n",
    "* age             Age\n",
    "* sibsp           Number of Siblings/Spouses Aboard\n",
    "* parch           Number of Parents/Children Aboard\n",
    "* ticket          Ticket Number\n",
    "* fare            Passenger Fare\n",
    "* cabin           Cabin\n",
    "* embarked        Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "adb23194-250e-44d9-8dad-524de9c54bbf",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genderclassmodel.csv  gendermodel.csv  test.csv  train.csv  train.csv.ori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries \n",
    "# installed\n",
    "# It is defined by the kaggle/python docker image: \n",
    "# https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) \n",
    "# will list the files in the input directory\n",
    "\n",
    "import sh\n",
    "print(sh.ls('./input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_cell_guid": "e703e996-ca79-4c6a-ace1-bed7e5010918",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 418 rows and 11 columns.\n",
      "test set has 418 rows and 2 columns.\n",
      "train set has 891 rows and 12 columns.\n"
     ]
    }
   ],
   "source": [
    "Y_test =  pd.read_csv('./input/genderclassmodel.csv')\n",
    "test =  pd.read_csv('./input/test.csv')\n",
    "train =  pd.read_csv('./input/train.csv')\n",
    "\n",
    "print('test set has %s rows and %s columns.' % test.shape)\n",
    "print('test set has %s rows and %s columns.' % Y_test.shape)\n",
    "print('train set has %s rows and %s columns.' % train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, p_unique=0.2):\n",
    "    df = df.copy()\n",
    "    \n",
    "    size = len(df)\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    for c in cols:\n",
    "        if df[c].dtype == object:\n",
    "            if df[c].nunique()/size > p_unique:\n",
    "                df.drop(c, axis=1, inplace=True)\n",
    "                continue\n",
    "                \n",
    "            df = pd.concat([\n",
    "                df.drop(c, axis=1), \n",
    "                pd.get_dummies(df[c], drop_first=True)\n",
    "            ], axis=1)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train.copy()\n",
    "\n",
    "train_.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "train_.dropna(inplace=True)\n",
    "\n",
    "X_train = prepare_df(train_.drop('Survived', axis=1))\n",
    "y_train = train_[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = pd.concat([Y_test, test.iloc[:, 1:]], axis=1)\n",
    "\n",
    "test_.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_.dropna(inplace=True)\n",
    "\n",
    "X_test = prepare_df(test_.drop('Survived', axis=1))\n",
    "y_test = test_[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test set has 331 rows and 8 columns.\n",
      "y_test set has 331 rows and 1 columns.\n",
      "X_train set has 712 rows and 8 columns.\n",
      "Y_train set has 712 rows and 1 columns.\n"
     ]
    }
   ],
   "source": [
    "print('X_test set has %s rows and %s columns.' % X_test.shape)\n",
    "print('y_test set has %s rows and %s columns.' % y_test.shape)\n",
    "print('X_train set has %s rows and %s columns.' % X_train.shape)\n",
    "print('Y_train set has %s rows and %s columns.' % y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    RandomForestClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "f1 score\n",
      "0.761904761904762\n",
      "precision score\n",
      "0.732824427480916\n",
      "accuracy score\n",
      "0.8187311178247734\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "f1 score\n",
      "0.4621513944223108\n",
      "precision score\n",
      "0.4461538461538462\n",
      "accuracy score\n",
      "0.5921450151057401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmn/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/home/xmn/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
    "f1 score\n",
    "0.768558951965\n",
    "precision score\n",
    "1.0\n",
    "accuracy score\n",
    "0.873205741627\n",
    "\n",
    "\n",
    "<class 'sklearn.svm.classes.SVC'>\n",
    "f1 score\n",
    "0.873015873016\n",
    "precision score\n",
    "0.990990990991\n",
    "accuracy score\n",
    "0.923444976077\n",
    "'''\n",
    "for model in [RandomForestClassifier(), SVC()]:\n",
    "    print('\\n%s' % model)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted = model.predict(X_test)\n",
    "    print('f1 score')\n",
    "    print(f1_score(y_test, predicted))\n",
    "    print('precision score')\n",
    "    print(precision_score(y_test, predicted))\n",
    "    print('accuracy score')\n",
    "    print(accuracy_score(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_active": false,
    "_cell_guid": "a841197c-c6ff-4816-2a74-6a62c3bb461d",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted.to_csv('output/svc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
